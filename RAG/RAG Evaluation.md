## Challenges and Considerations

- **Ambiguity** in languages (i.e. homonyms)
- **Noise** typos, inconsistencies, irrelevant information
- **Scalability** 
- **Quality** of the knowledge graph extraction from the data
- **Subjectivity** evaluation quality depends on expertise of the evaluators
- **Data Availability** obtaining of high-quality dataset might be challenging
- **Computational Cost**
- **Evaluation Metrics** determining and measuring appropriate metrics might be difficult

## Quality Assessment and Evaluation

- **Accuracy** extend to which the information is correct and factual
- **Completeness** the degree to which the information covers all relevant entities and relationships
- **Consistency** the degree to which the information is free from contradictions
- **Relevance** the extend to which the information is relevant to the use-case

## Evaluation Techniques

- **Manual/Human Evaluation** inspecting knowledge graph by experts and comparing to known information
- **Automated Evaluation** calculated by comparing a reference dataset with the knowledge graph 
	- Entity Coverage
	- Relation Coverage 
	- Fact Coverage
	- Accuracy Metrics: Precision, Recall, F1-score
	- Consistency Metrics: logical consistency checks

Automated evaluation can be done by comparing with [[Reference Datasets]].
